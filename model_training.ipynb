{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b14f4b06-0348-4da2-9250-92d2814f2d1b",
   "metadata": {},
   "source": [
    "# From Notebook to ModelOp Center:\n",
    "\n",
    "## Training, Evaluating, and Conforming a Model for Deployment\n",
    "In this notebook, we demonstrate the process of\n",
    "1. training a model,\n",
    "2. evaluating its performance,\n",
    "3. saving for later use,\n",
    "4. and conforming it to MOC standards\n",
    "\n",
    "More specifically, we will train a linear regression predictor on the Ames Housing Data dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2609ff9-67af-4bb8-842b-cb7495b6c7e6",
   "metadata": {},
   "source": [
    "**I - Model Training**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bcec1b-1010-4849-8914-f89b34a9f6f6",
   "metadata": {},
   "source": [
    "Let's load in the necessary libraries. We will be using `sklearn` to train the model, and `aequitas` for bias detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc8287e8-d6b2-451d-8925-3ba5b2057d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas\n",
    "import numpy\n",
    "import copy\n",
    "\n",
    "from aequitas.bias import Bias\n",
    "from aequitas.group import Group\n",
    "from aequitas.preprocessing import preprocess_input_df\n",
    "\n",
    "from sklearn import set_config\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "\n",
    "set_config(display='diagram')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56875f16-a0b1-4a32-be46-0034cf69522f",
   "metadata": {},
   "source": [
    "The **Ames Housing Data** dataset can be found [at this link](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data). Download the train dataset (we will be using it exclusively as those have all have an actual SalePrice value, our ground truth to use with the monitoring capabilities of ModelOp Center) and load it into a Pandas DataFrame. For the purposes of showcasing monitoring capabilities, we will add a randomly generated feature for each row, `gender`, for demonstration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e204a16-e80f-46b0-af4b-a58ca6ca2c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_csv('./house_price_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "786b47b6-0606-439a-a828-dcd839c66a10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Id', 'MSSubClass', 'MSZoning', 'LotFrontage', 'LotArea', 'Street',\n",
       "       'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig',\n",
       "       'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n",
       "       'BldgType', 'HouseStyle', 'OverallQual', 'OverallCond',\n",
       "       'YearBuilt', 'YearRemodAdd', 'RoofStyle', 'RoofMatl',\n",
       "       'Exterior1st', 'Exterior2nd', 'MasVnrType', 'MasVnrArea',\n",
       "       'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond',\n",
       "       'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2',\n",
       "       'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'Heating', 'HeatingQC',\n",
       "       'CentralAir', 'Electrical', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF',\n",
       "       'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
       "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual',\n",
       "       'TotRmsAbvGrd', 'Functional', 'Fireplaces', 'FireplaceQu',\n",
       "       'GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageCars',\n",
       "       'GarageArea', 'GarageQual', 'GarageCond', 'PavedDrive',\n",
       "       'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch',\n",
       "       'ScreenPorch', 'PoolArea', 'PoolQC', 'Fence', 'MiscFeature',\n",
       "       'MiscVal', 'MoSold', 'YrSold', 'SaleType', 'SaleCondition',\n",
       "       'SalePrice'], dtype=object)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd1ecfd-4a22-4592-8267-25b983a7a033",
   "metadata": {},
   "source": [
    "Let's look at the top of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fe9c8d6-f546-4f6c-a136-60473a1423cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Alley</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>...</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>PoolQC</th>\n",
       "      <th>Fence</th>\n",
       "      <th>MiscFeature</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 81 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
       "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
       "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
       "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
       "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
       "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
       "\n",
       "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
       "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
       "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
       "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
       "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
       "\n",
       "  YrSold  SaleType  SaleCondition  SalePrice  \n",
       "0   2008        WD         Normal     208500  \n",
       "1   2007        WD         Normal     181500  \n",
       "2   2008        WD         Normal     223500  \n",
       "3   2006        WD        Abnorml     140000  \n",
       "4   2008        WD         Normal     250000  \n",
       "\n",
       "[5 rows x 81 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581b0007-5c5c-415f-af54-80c128acda68",
   "metadata": {},
   "source": [
    "Before proceeding with model development, we will split the original dataset into two sets: a **baseline** set which will be used as a reference set, and a **sample** set which will mimic input data to the model once the model is in use.\n",
    "\n",
    "We'l also prepare a `_scored` version of the dataframes for later use during our MOC monitoring phase. In that DataFrame, we'll mainly be using the `ground_truth`, which in our case is `SalePrice`, and `predictions` (later to be added) to compare drift, bias, and other metrics that we will want to monitor in the lifecycle of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff1d4f07-92de-41cf-ac12-0c6849be5256",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baseline, df_sample = train_test_split(df, train_size=0.8, random_state=0)\n",
    "\n",
    "df_baseline_scored = df_baseline.copy(deep=True)\n",
    "df_sample_scored = df_sample.copy(deep=True)\n",
    "\n",
    "df_baseline.to_json('df_baseline.json', orient='records', lines=True)\n",
    "df_sample.to_json('df_sample.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8bc85a-8100-45dd-a74f-2522faf896b6",
   "metadata": {},
   "source": [
    "We will have to **clean up** the data. There are quite a few null values in the dataset and, although effort to properly impute and clean data is necessary, we will only apply simple imputations for the sake of this demonstration. Note that these steps will also be necessary once we want to write code that conforms to ModelOp standards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b279bfc-1cb0-4f8e-a6b0-9a7716ad6738",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features = []\n",
    "categorical_features = []\n",
    "for i,j in zip(df.dtypes.index, df.dtypes.values):\n",
    "    if j=='object':\n",
    "        categorical_features.append(i)\n",
    "    else:\n",
    "        numerical_features.append(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5081129-3312-4f4a-96c3-03bd2a900f3a",
   "metadata": {},
   "source": [
    "**Categorical Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fbd62d73-ac0e-4ca7-8412-e2f49b321106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition']\n"
     ]
    }
   ],
   "source": [
    "print(categorical_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf47a782-66af-4c21-a699-8f43c458c680",
   "metadata": {},
   "source": [
    "**Numerical Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c07dc39-9c20-4422-ae74-7aa86b81880a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Id', 'MSSubClass', 'LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', '1stFlrSF', '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', 'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'MoSold', 'YrSold', 'SalePrice']\n"
     ]
    }
   ],
   "source": [
    "print(numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cddebcdf-acd7-4c22-8fe8-1724b6b5a553",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/royk/.local/lib/python3.8/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n"
     ]
    }
   ],
   "source": [
    "# imputing missing GarageYrBlt values with corresponding YrBlt values\n",
    "df_baseline.loc[:,'GarageYrBlt'] = [df_baseline.loc[i, 'GarageYrBlt'] if not x else df_baseline.loc[i, 'YearBuilt'] for i, x in df_baseline.loc[:,'GarageYrBlt'].isna().items()]\n",
    "df_sample.loc[:,'GarageYrBlt'] = [df_sample.loc[i, 'GarageYrBlt'] if not x else df_sample.loc[i, 'YearBuilt'] for i, x in df_sample.loc[:,'GarageYrBlt'].isna().items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f049f4e-6690-4e4e-965d-c07fd08eaaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputing all missing values in numerical features with 0\n",
    "for col in numerical_features:\n",
    "    df_baseline.loc[:, col] = df_baseline.loc[:, col].fillna(0)\n",
    "    df_sample.loc[:, col] = df_sample.loc[:, col].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "28e08268-933d-49aa-8154-3fa41d87f431",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imputing all missing values in categorical features with 'None'\n",
    "for col in categorical_features:\n",
    "    df_baseline.loc[:, col] = df_baseline.loc[:, col].fillna('None')\n",
    "    df_sample.loc[:, col] = df_sample.loc[:, col].fillna('None')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c9fdbe5-f8af-4d9d-b333-14cb0f3c7cb1",
   "metadata": {},
   "source": [
    "Our data still contains non-predictive features, such as `Id` and `SalePrice`. We remove those now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b504c5a6-f2f4-46c9-bfbb-305190143a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictive_features = [\n",
    "    f for f in list(df.columns.values)\n",
    "    if f not in ['Id', 'SalePrice']\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1caa7ec5-eee8-48b3-b927-1dcdb95aa806",
   "metadata": {},
   "source": [
    "Everything looks good; we'll proceed with model training. We need to specify **predictive** and **responsive** variables for each of the training and test sets. We'll set those by filtering the baseline and sample sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f451b1a-ce10-4209-a6bb-9648aa86ebc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_baseline[predictive_features]\n",
    "X_test = df_sample[predictive_features]\n",
    "\n",
    "y_train = df_baseline['SalePrice']\n",
    "y_test = df_sample['SalePrice']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339f0104-5e02-455b-a22d-c73294457a06",
   "metadata": {},
   "source": [
    "Will will train a **Lasso** linear regression model. Since our data contains categorical features, we will need to one-hot encode using `pandas.get_dummies()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20eff431-2249-47e1-b979-253e77c3c009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding with pandas.get_dummies()\n",
    "X_train = pandas.get_dummies(X_train, columns=categorical_features)\n",
    "X_test = pandas.get_dummies(X_test, columns=categorical_features)\n",
    "\n",
    "# The final list of encoded columns\n",
    "train_encoded_columns = X_train.columns\n",
    "\n",
    "# filling in any missing encoded columns with 0s\n",
    "for col in train_encoded_columns:\n",
    "    if col not in X_test.columns:\n",
    "        X_test[col] = numpy.zeros(X_test.shape[0])\n",
    "\n",
    "# restricting X_test columns to only be final list of encoded columns\n",
    "X_test = X_test[train_encoded_columns]\n",
    "\n",
    "# Saving the final list of encoded columns\n",
    "pickle.dump(train_encoded_columns, open('train_encoded_columns.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66326deb-24b0-4f05-8a9c-6e8f66626611",
   "metadata": {},
   "source": [
    "Let's fit the model to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fde628ce-c868-42c9-83fa-a3b274a66424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.sk-top-container {color: black;background-color: white;}div.sk-toggleable {background-color: white;}label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}div.sk-estimator:hover {background-color: #d4ebff;}div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}div.sk-item {z-index: 1;}div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}div.sk-parallel-item:only-child::after {width: 0;}div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}div.sk-label-container {position: relative;z-index: 2;text-align: center;}div.sk-container {display: inline-block;position: relative;}</style><div class=\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"a2a7b257-90f1-475d-ab0b-879934ddc94c\" type=\"checkbox\" checked><label class=\"sk-toggleable__label\" for=\"a2a7b257-90f1-475d-ab0b-879934ddc94c\">LassoCV</label><div class=\"sk-toggleable__content\"><pre>LassoCV()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LassoCV()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = LassoCV()\n",
    "lasso.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7320916d-d493-455b-a6b9-151fa0ac4985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7708447275907354"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cf77e7-1d0f-406f-b2aa-8c1a4f6e9e33",
   "metadata": {},
   "source": [
    "**II - Model Evaluation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d89a1a5-b3a8-496d-a943-be4e466e1c7c",
   "metadata": {},
   "source": [
    "Before saving our trained model for further use, let's take a look at some performance metrics. We will evaluate the model on both the training and test sets; we want to see a stable performance between the two.  \n",
    "\n",
    "For repeatability, let's define a function which computes multiple metrics at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0d2ba1e7-43ce-4f99-9306-31fa6a3aa309",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y, y_preds):\n",
    "    \"\"\"\n",
    "    A function to evaluate a regression model.\n",
    "    \n",
    "    param: y: true (ground truth) values\n",
    "    param: y_preds: predicted values (as predicted by model)\n",
    "    \n",
    "    return: multiple regression performance metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    return {\n",
    "        'Mean Absolute Error' : mean_absolute_error(y, y_preds),\n",
    "        'Root Mean Squared Error' : mean_squared_error(y, y_preds) ** 0.5,\n",
    "        'R2 Score' : r2_score(y, y_preds)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4951c4b-dd43-4d2e-986c-aa16ea36a086",
   "metadata": {},
   "source": [
    "Let's compute predictions on both training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d00e0c2-f32e-4063-834d-1f81ea0e0c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds = lasso.predict(X_train)\n",
    "y_test_preds = lasso.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d29e6690-5dd0-4596-b57b-013dd2afa321",
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df = pandas.DataFrame(\n",
    "    data=[{}],\n",
    "    columns=['Mean Absolute Error', 'Root Mean Squared Error', 'R2 Score'],\n",
    "    index=['Training Set', 'Test Set']\n",
    ")\n",
    "performance_df.loc['Training Set', :] = compute_metrics(y_train, y_train_preds)\n",
    "performance_df.loc['Test Set', :] = compute_metrics(y_test, y_test_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb5a8c1-dad8-4f55-84a8-8e91b7276f79",
   "metadata": {},
   "source": [
    "Let's look at how our model performed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5aa2f26-cbcc-47a4-a900-53ed530690da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Absolute Error</th>\n",
       "      <th>Root Mean Squared Error</th>\n",
       "      <th>R2 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training Set</th>\n",
       "      <td>24576.407762</td>\n",
       "      <td>37561.947354</td>\n",
       "      <td>0.770845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Test Set</th>\n",
       "      <td>27946.183300</td>\n",
       "      <td>58544.859989</td>\n",
       "      <td>0.503682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Mean Absolute Error  Root Mean Squared Error  R2 Score\n",
       "Training Set         24576.407762             37561.947354  0.770845\n",
       "Test Set             27946.183300             58544.859989  0.503682"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0ca6d2-87f5-49a2-9d0e-bc3b4f460e64",
   "metadata": {},
   "source": [
    "There is quite a difference in performance between the training set and the test set, showing some amount of overfitting. Further model improvements are needed to achieve more accurate inferences. For now, we will contend with this model and use it to produce new predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d5218d7-072c-4224-ba4c-97c249c409fa",
   "metadata": {},
   "source": [
    "**III - Saving and Loading the Trained Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d005abc3-69d1-4876-bdd8-3cf9ec00e52b",
   "metadata": {},
   "source": [
    "Now that the model is **trained** and **evaluated**, we save it in a binary format. It will later be loaded and used to make new predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7327c52-1986-400b-80ab-815a7ad83a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(lasso, open('lasso.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85915ca-4140-4be1-a775-861d7775a7d8",
   "metadata": {},
   "source": [
    "The model is reloaded on-demands as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80259dcc-5e75-4c6a-9744-640fdf443127",
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_loaded = pickle.load(open('lasso.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398ddc31-8426-4c1b-9231-3f1bd9c75c91",
   "metadata": {},
   "source": [
    "Predictions can be produced on-demand by calling the `predict()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "231f274f-8508-42b8-ae2d-3a798cfe6b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_preds = lasso_loaded.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14e12e4-4232-48ea-b69b-6718b3b9b83f",
   "metadata": {},
   "source": [
    "Before heading into the next section, let's append our predictions to our `_scored` DataFrames and save them. Once again, these data sets will be used mainly for monitoring purposes. Specifically for Regression models, MOC expected the ground truth (actual) column to be named `ground_truth` and the predictions to be named `predictions`. We'll make those changes and save our data sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9827aae-e0a4-47dc-a70b-1c4fddd4af2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_baseline_scored['predictions'] = y_train_preds\n",
    "df_baseline_scored = df_baseline_scored.rename(columns={'SalePrice':'ground_truth'})\n",
    "\n",
    "df_sample_scored['predictions'] = y_test_preds\n",
    "df_sample_scored = df_sample_scored.rename(columns={'SalePrice':'ground_truth'})\n",
    "                                           \n",
    "df_baseline_scored.to_json('df_baseline_scored.json', orient='records', lines=True)\n",
    "df_sample_scored.to_json('df_sample_scored.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6285e0fa-f428-478f-bd57-da9f18203e4a",
   "metadata": {},
   "source": [
    "**IV - Evaluating Bias on Protected Classes**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b9d85e-ecd3-4b2c-a62c-e8cdccf0f98f",
   "metadata": {},
   "source": [
    "*Work in progress*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710a39cb-4ab9-4faf-9c95-e3c3b9c11eeb",
   "metadata": {},
   "source": [
    "**V - Conforming Model Code to MOC Requirements**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599c419c-bfed-431a-942f-a83f314fd073",
   "metadata": {},
   "source": [
    "Conformance is best demonstrated through example. Let's look at the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "326853da-70d4-41d7-8759-75bba35f2b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import pickle\n",
    "import copy\n",
    "from aequitas.preprocessing import preprocess_input_df\n",
    "from aequitas.group import Group\n",
    "from aequitas.bias import Bias\n",
    "\n",
    "# modelop.init\n",
    "def begin():\n",
    "    global lasso_model\n",
    "    \n",
    "    # load pickled Lasso linear regression model\n",
    "    lasso_model = pickle.load(open('lasso.pickle', 'rb'))\n",
    "    # load train_encoded_columns\n",
    "    train_encoded_columns = pickle.load(open('train_encoded_columns.pickle', 'rb'))\n",
    "\n",
    "# modelop.score\n",
    "def action(data):\n",
    "    # Turn data into DataFrame\n",
    "    df = pandas.DataFrame(data)\n",
    "    \n",
    "    predictive_features = ['MSSubClass', 'MSZoning', 'LotFrontage',\n",
    "                           'LotArea', 'Street', 'Alley', 'LotShape',\n",
    "                           'LandContour', 'Utilities', 'LotConfig',\n",
    "                           'LandSlope', 'Neighborhood', 'Condition1',\n",
    "                           'Condition2', 'BldgType', 'HouseStyle',\n",
    "                           'OverallQual', 'OverallCond', 'YearBuilt',\n",
    "                           'YearRemodAdd', 'RoofStyle', 'RoofMatl', \n",
    "                           'Exterior1st', 'Exterior2nd', 'MasVnrType',\n",
    "                           'MasVnrArea', 'ExterQual', 'ExterCond',\n",
    "                           'Foundation', 'BsmtQual', 'BsmtCond',\n",
    "                           'BsmtExposure', 'BsmtFinType1', 'BsmtFinSF1',\n",
    "                           'BsmtFinType2', 'BsmtFinSF2', 'BsmtUnfSF',\n",
    "                           'TotalBsmtSF', 'Heating', 'HeatingQC',\n",
    "                           'CentralAir', 'Electrical', '1stFlrSF',\n",
    "                           '2ndFlrSF', 'LowQualFinSF', 'GrLivArea',\n",
    "                           'BsmtFullBath', 'BsmtHalfBath', 'FullBath',\n",
    "                           'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr',\n",
    "                           'KitchenQual', 'TotRmsAbvGrd', 'Functional',\n",
    "                           'Fireplaces', 'FireplaceQu', 'GarageType',\n",
    "                           'GarageYrBlt', 'GarageFinish', 'GarageCars',\n",
    "                           'GarageArea', 'GarageQual', 'GarageCond',\n",
    "                           'PavedDrive', 'WoodDeckSF', 'OpenPorchSF',\n",
    "                           'EnclosedPorch', '3SsnPorch', 'ScreenPorch',\n",
    "                           'PoolArea', 'PoolQC', 'Fence', 'MiscFeature',\n",
    "                           'MiscVal', 'MoSold', 'YrSold', 'SaleType',\n",
    "                           'SaleCondition']\n",
    "    \n",
    "    categorical_features = ['MSZoning', 'Street', 'Alley', 'LotShape',\n",
    "                            'LandContour', 'Utilities', 'LotConfig',\n",
    "                            'LandSlope', 'Neighborhood', 'Condition1',\n",
    "                            'Condition2', 'BldgType', 'HouseStyle',\n",
    "                            'RoofStyle', 'RoofMatl', 'Exterior1st', \n",
    "                            'Exterior2nd', 'MasVnrType', 'ExterQual',\n",
    "                            'ExterCond', 'Foundation', 'BsmtQual',\n",
    "                            'BsmtCond', 'BsmtExposure', 'BsmtFinType1', \n",
    "                            'BsmtFinType2', 'Heating', 'HeatingQC',\n",
    "                            'CentralAir', 'Electrical', 'KitchenQual',\n",
    "                            'Functional', 'FireplaceQu', 'GarageType',\n",
    "                            'GarageFinish', 'GarageQual', 'GarageCond',\n",
    "                            'PavedDrive', 'PoolQC', 'Fence',\n",
    "                            'MiscFeature', 'SaleType', 'SaleCondition']\n",
    "    \n",
    "    # imputing missing values\n",
    "    for col in predictive_features:\n",
    "        if df.loc[:,col].isna().sum()>0:\n",
    "            if df.loc[:,col].dtype=='object':\n",
    "                df.loc[:,col] = df.loc[:,col].fillna('None')\n",
    "            else:\n",
    "                df.loc[:,col] = df.loc[:,col].fillna(0)\n",
    "    \n",
    "    # one-hot encode\n",
    "    df = pandas.get_dummies(df, columns=categorical_features)\n",
    "\n",
    "    # filling in any missing encoded columns with 0s\n",
    "    for col in train_encoded_columns:\n",
    "        if col not in df.columns:\n",
    "            df[col] = numpy.zeros(df.shape[0])\n",
    "\n",
    "    # restricting columns to only be final list of encoded columns\n",
    "    df = df[train_encoded_columns]\n",
    "    \n",
    "    df['predictions'] = lasso_model.predict(df)\n",
    "    \n",
    "    # MOC expects the action function to be a \"yield\" function\n",
    "    return df.to_dict(orient='records')\n",
    "    # yield df.to_dict(orient='records')\n",
    "\n",
    "# modelop.metrics\n",
    "def metrics(data):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09dc4fa9-f569-46a1-bdb9-50f78167869e",
   "metadata": {},
   "source": [
    "There are four main sections that are standard to almost any model in MOC:\n",
    "1. Library imports\n",
    "2. `init` function\n",
    "3. `score` function\n",
    "4. `metrics` function\n",
    "\n",
    "**Library** imports are always at the top. We don't need to include all libraries that we used for training and model evaluation. We just need the libraries for processing and scoring.\n",
    "\n",
    "The **`init`** function runs once per deployment, and is used to load and persist into memory any variable that needs to be accessed at scoring time. For example, the init function is where we load the saved model binary. We make the variable global so it can be accessed from the scoring function. In our example, we also included the `train_encoded_columns` as this information will not change per prediction and only needs to be instantiated once.\n",
    "\n",
    "The **`score`** function is the function that runs anytime we make a scoring (prediction) request. This is where we put our prediction code. We have to remember to include any steps that were not captured by the pipeline, such as feature engineering or re-encoding.\n",
    "\n",
    "The **`metrics`** functions is where model evaluation is carried out. In our example, this is the place where we replicate the calculations of Group and/or Bias metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cfc87bd-0b91-4105-8e3a-bde4722bbb6e",
   "metadata": {},
   "source": [
    "Let us test our source code to see if we missed anything. We will load input data and scored input data to test both the scoring and metrics functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1c9892df-0b79-4257-b80a-3a38d04de6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = pandas.read_json('df_baseline.json', orient='records', lines=True)\n",
    "metrics_sample = pandas.read_json('df_baseline_scored.json', orient='records', lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ab826e-a7f5-436e-b5c8-d8c5e99b3020",
   "metadata": {},
   "source": [
    "Let's check that the **`init`** function can load the trained model binary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b249f703-a42d-4739-96d9-7b5e6b88bdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "begin()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f550df5-91cd-436b-b590-457a9150141c",
   "metadata": {},
   "source": [
    "No errors from the **`init`** function. Let's make a call to the **`score`** function on input data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6c01c2bf-f553-42b9-aefb-94975daec974",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = action(test_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef6f273-bc91-464f-8c88-20e9114d12ec",
   "metadata": {},
   "source": [
    "We have a set of scores! Finally, let's call the **`metrics`** function on scored data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a4039f-a10f-464b-893a-99d19ea88171",
   "metadata": {},
   "source": [
    "*Work in progress*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
